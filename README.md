# LM Studio + AnythingLLM Quick Setup Guide

Easily run powerful language models locally with LM Studio and AnythingLLM.


![lmstudioanythingllm](https://github.com/user-attachments/assets/f41f764f-79cd-4806-af6f-9152ca8d96f8)

## Prerequisites

- [LM Studio](https://lmstudio.ai) installed
- [AnythingLLM](https://anythingllm.com/) installed
- Sufficient RAM and processing power for running large language models

## Quick Setup

### 1. LM Studio Setup

1. Launch LM Studio
2. Go to the "Developer" tab
3. In the "Local Server" section:
   - Load a model
   - Click "Start Server"
![image](https://github.com/user-attachments/assets/c0ad8f3c-cc94-4a9b-8e4f-962b11307e4a)


### 2. AnythingLLM Configuration

1. Launch AnythingLLM
2. Create a new workspace (name it whatever you like)
3. Click on Settings (‚öôÔ∏è)
4. Navigate to "Chat Settings"
5. Select "LM Studio" as the provider

![image](https://github.com/user-attachments/assets/ca25af40-424e-4836-b167-83d42708951f)


### 3. Start Chatting

- Use the default AnythingLLM chat interface to start interacting with your chosen LLM

## Tips

- Keep LM Studio running in the background while using AnythingLLM
- For optimal performance, choose a model that fits your hardware capabilities

## Troubleshooting

- **Connection issues?** Verify LM Studio's server is running and check the address in AnythingLLM
- **Slow responses?** Consider using a smaller model or upgrading your hardware

## Need Help?

- [LMStudio Docs](https://lmstudio.ai/docs)
- [AnythingLLM](https://github.com/Mintplex-Labs/anything-llm)

Happy chatting with your local LLM! üöÄ
